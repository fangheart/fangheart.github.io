<!doctype html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="机器学习,有监督学习,无监督学习,线性分类器,SVM支持向量机,logistic回归,随机梯度,贝叶斯模型,K邻近,决策树,集成模型,随机森林,极端随机森林,梯度提升决策树,数据聚类（K-means）," />








  <link rel="shortcut icon" type="image/x-icon" href="/personnal/favicon.ico?v=5.1.0" />






<meta name="description" content="基本知识1.1.1 机器学习的任务机器学习的任务种类较多，但是常规来讲可以以监督学习（Supervised Learning）和无监督学习（Unsupervised Learning）。其中监督学习关注对事物未知表现的预测，一般包括分类问题（classification）、回归问题（Regression）。无监督学习则倾向于对事物本身特性的分析，常用的技术包括数据降维（Dimensionality">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习基础-有监督模型（分类、回归）、无监督模型（聚合、降维）">
<meta property="og:url" content="http://www.fangheart.top/2017/06/11/机器学习基础-有监督模型（分类、回归）、无监督模型（聚合、降维）/index.html">
<meta property="og:site_name" content="FangHeart's blog">
<meta property="og:description" content="基本知识1.1.1 机器学习的任务机器学习的任务种类较多，但是常规来讲可以以监督学习（Supervised Learning）和无监督学习（Unsupervised Learning）。其中监督学习关注对事物未知表现的预测，一般包括分类问题（classification）、回归问题（Regression）。无监督学习则倾向于对事物本身特性的分析，常用的技术包括数据降维（Dimensionality">
<meta property="og:image" content="http://ocef6bnjz.bkt.clouddn.com/17-6-11/34873578.jpg">
<meta property="og:image" content="http://ocef6bnjz.bkt.clouddn.com/17-6-11/75506981.jpg">
<meta property="og:image" content="http://ocef6bnjz.bkt.clouddn.com/17-6-11/17242026.jpg">
<meta property="og:updated_time" content="2017-06-11T14:51:30.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习基础-有监督模型（分类、回归）、无监督模型（聚合、降维）">
<meta name="twitter:description" content="基本知识1.1.1 机器学习的任务机器学习的任务种类较多，但是常规来讲可以以监督学习（Supervised Learning）和无监督学习（Unsupervised Learning）。其中监督学习关注对事物未知表现的预测，一般包括分类问题（classification）、回归问题（Regression）。无监督学习则倾向于对事物本身特性的分析，常用的技术包括数据降维（Dimensionality">
<meta name="twitter:image" content="http://ocef6bnjz.bkt.clouddn.com/17-6-11/34873578.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://www.fangheart.top/2017/06/11/机器学习基础-有监督模型（分类、回归）、无监督模型（聚合、降维）/"/>





  <title> 机器学习基础-有监督模型（分类、回归）、无监督模型（聚合、降维） | FangHeart's blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">FangHeart's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">爱生活，爱编码。</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocapitalize="off" autocomplete="off" autocorrect="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://www.fangheart.top/2017/06/11/机器学习基础-有监督模型（分类、回归）、无监督模型（聚合、降维）/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="FangHeart">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/personnal/author.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FangHeart's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                机器学习基础-有监督模型（分类、回归）、无监督模型（聚合、降维）
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-06-11T17:10:15+08:00">
                2017-06-11
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a class="cloud-tie-join-count" href="/2017/06/11/机器学习基础-有监督模型（分类、回归）、无监督模型（聚合、降维）/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count join-count" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2017/06/11/机器学习基础-有监督模型（分类、回归）、无监督模型（聚合、降维）/" class="leancloud_visitors" data-flag-title="机器学习基础-有监督模型（分类、回归）、无监督模型（聚合、降维）">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="基本知识"><a href="#基本知识" class="headerlink" title="基本知识"></a>基本知识</h2><h3 id="1-1-1-机器学习的任务"><a href="#1-1-1-机器学习的任务" class="headerlink" title="1.1.1 机器学习的任务"></a>1.1.1 机器学习的任务</h3><p>机器学习的任务种类较多，但是常规来讲可以以监督学习（Supervised Learning）和无监督学习（Unsupervised Learning）。其中监督学习关注对事物未知表现的预测，一般包括分类问题（classification）、回归问题（Regression）。无监督学习则倾向于对事物本身特性的分析，常用的技术包括数据降维（Dimensionality Reduction）和聚类问题（Clustering）。</p>
<p>分类问题，便是对其所在类别进行预测，类别是离散的，同时也是预先知道数量的。例如根据一个人的身高、体重和三维判定性别，性别是离散的，男和女，同时预先知道其数量。或者说更经典的例子，根据鸢尾花的花瓣、花萼的长宽等数据，判断其所属的鸢尾花亚种，因为鸢尾花的亚种的种类和数量也满足离散和预先知道这两项特征，因此也是分类预测问题。</p>
<p>回归同样是预测问题，只是预测的目标往往是连续的变量，比如根据房屋的面积、地理位置、建筑年代等对房屋销售价格进行预测，销售价格一定是一个连续的变量。</p>
<p>数据降维度是对事物的特征进行压缩和筛选。如果没有特定领域的知识，无法预先确定采样哪些数据，而现如今采样数据成本较低，但是筛选的成本比较高，比如在图像识别中，如今像素分辨率极大，因而若直接使用这些像素信息那么数据维度非常高，所以很难对数据进行处理。因此这样的数据通常需要进行降维，保存其最有区分度的像素组合，从此便能不影响效果，但是数据维度降低，降低运算难度，也更容易理解。</p>
<p>聚类则是依赖于数据的相似性，把相似的数据样本划分为一个簇，不同于分类问题，我们在大多数情况下不会预先知道簇的数量和每个簇的具体含义。例如购物网站对用户信息和购买习惯进行聚类分析，这样就可以进行分类的广告投放。</p>
<h3 id="1-1-2-机器学习中应用的经验"><a href="#1-1-2-机器学习中应用的经验" class="headerlink" title="1.1.2 机器学习中应用的经验"></a>1.1.2 机器学习中应用的经验</h3><p>习惯性的认为数据就是经验，只有那些对学习任务有用的特定信息才会被列入考虑范围，通常把这些反映数据内在规律的信息叫做特征（Feature）。譬如经典的人脸识别，很少直接用原始图像来进行经验来学习，而是先进行建委，把复杂的数据处理成有助于人脸识别的轮廓特征。</p>
<p>对于监督学习问题，所需要的经验一般包括特征，以及标记/目标(Label/Target)这样才能知道结果是什么，标记/目标的表现形式则取决于监督学习的种类。</p>
<p>无监督学习并不用于做结果预测，那么自然就不需要标记/目标，但是却更加适合对于数据结构的分析。正式因为这个区别可以尝尝获得大量无监督数据，而监督数据的标注因为经常耗费大量的时间、金钱和人力，所以数据量相对较少。</p>
<p>更重要的是，标记/目标的表现形式存在离散、连续变量的区别，从原始数据到特征数据的转换过程中也会遭遇到多种数据类型：类别型特征、数值型特征、甚至是缺失的数据。而学习的过程中需要将这些特征转换为具体的数据参与计算，所以通常要经过缺失数据补全、部分数据过滤、和数据标准化等预先对数据进行处理。</p>
<pre><code>而通常所说的训练集就是既有特征，同时带有目标/标记的数据集。
</code></pre><h3 id="1-1-3-机器学习的性能、精度表现形式"><a href="#1-1-3-机器学习的性能、精度表现形式" class="headerlink" title="1.1.3 机器学习的性能、精度表现形式"></a>1.1.3 机器学习的性能、精度表现形式</h3><p>所谓的性能，便是评价完成任务的质量指标。通常为了评价其完成的质量，我们需要具有相同特征的数据，并将模型的预测结果与相对应的正确结果进行对比。这样的数据成为测试集。（测试集的数据一定不能出现在训练集中，也就是说他们说相互排斥的。）</p>
<p>预测精度问题：</p>
<pre><code>- 对于分类问题来讲，需要根据预测正确类别的百分比来评判其性能，这个指标也通常成为准确性（Accuracy）.
- 对于回归问题需要衡量预测值与实际值之间的偏差大小。
- 而通常这两种预测指标的表现形式有些不足。对于分类问题一般还有召回率（Recall）、精确率（Percision）以及F1指标。
- 对于回归问题一般又有三种关于回归的特有的评价机制如R-squared。【p69】
- 对于聚类问题，如果评估的数据有具体的所属类别，一般采用ARI（Adjust Rand Index）指标，他与分类问题的准确性（Accuracy）类似，但是它也兼顾的考虑到了类簇无法和分类标记意义对应的问题。如果没有具体的所属类别，那么一般使用轮廓系数（Slihouette Coefficient）来度量聚类的结果质量。取值范围【-1，1】数值越大表明效果越好。【P85】
- 对于数据降维如PCA,一般用处理过的数据与未降维的数据来进行对比即可。对比参数可根据数据所属类别来选择。
</code></pre><h2 id="监督学习："><a href="#监督学习：" class="headerlink" title="监督学习："></a>监督学习：</h2><p>机器学习的监督学习模型的任务重点在于，根据已有经验的知识对未知样本的目标/标记进行预测，根据目标预测变量的类别不同，把监督学习任务大体分为分类学习与回归预测两类。<br><img src="http://ocef6bnjz.bkt.clouddn.com/17-6-11/34873578.jpg" alt=""><br>流程即如上体所示，首先需要准备训练数据，可以是文本、图像、音频等，然后抽取所需要的特征，形成特征向量（Feature Vectors），接着把这些特征向量连同对应的标记/目标（即结果）一同送入学习算法（Machine Learning Algorithm）中，训练出一个预测模型(Predictive Model)，然后采用同样的特征抽取方法作用于新的测试数据，得到用于测试的特征向量，最后使用预测模型对这些待测试的特征向量进行预测并得到结果（Expected Label）.</p>
<h3 id="2-1-1分类学习（Classifier）"><a href="#2-1-1分类学习（Classifier）" class="headerlink" title="2.1.1分类学习（Classifier）"></a>2.1.1分类学习（Classifier）</h3><p>分类学习是最为常见的监督学习问题，最为基础的是二分类问题，即是判断是非，从两个类别中选择一个作为预测结果，除此之外还有多类分类即是在多余两个类别中选择一个作为预测结果，甚至还有多标签多分类问题，多标签多分类问题判断一个样本是否同时属于多个不同的类别。</p>
<p>比如实际生活中，遇到许多分类问题，如医生对肿瘤性质进行判定，邮件系统对手写数字进行识别，互联网公司对新闻进行分类，生物学家对物种类型进行鉴定。</p>
<h4 id="2-1-1-1-线性分类器（Linear-Classifier）"><a href="#2-1-1-1-线性分类器（Linear-Classifier）" class="headerlink" title="2.1.1.1 线性分类器（Linear Classifier）"></a>2.1.1.1 线性分类器（Linear Classifier）</h4><p>模型介绍：线性分类器（Linear Classifiers），是一种假设特征与分类结果存在线性关系的模型，这个模型通过累加计算每个维度的特征与各自的权重的乘积来帮助决策。常用的有LogisticRegression与SGDClassifiler。</p>
<p>数据描述：采用UCI的良/恶性乳腺癌肿瘤预测，分别是逻辑斯蒂回归分类，与随机梯度下降分类。</p>
<p>性能分析：准确率（Accuracy）、召回率（Recall）、精确率（Percision）以及F1指标。</p>
<p>特点分析：线性分类器可以说是最为基本和常用的机器学习模型，尽管受限于数据特征与分类目标之间的线性假设，仍然可以在科学研究和工程实践中吧线性分类器作为基准，所使用的模型包括LogisticRegression与SGDClassifiler，相比较，前者对参数的计算采用精确的解析方式，计算时间长但是模型性略高，后者采取随机梯度下降算法估计模型参数，计算时间段，但是模型性能略低。一般而言顺联的数据规模如果超过10W条，考虑到时间的耗用等因素，运用随机梯度算法对模型参数进行估计。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 导入pandas与numpy工具包。</span></div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"></div><div class="line"><span class="comment"># 创建特征列表。</span></div><div class="line">column_names = [<span class="string">'Sample code number'</span>, <span class="string">'Clump Thickness'</span>, <span class="string">'Uniformity of Cell Size'</span>, <span class="string">'Uniformity of Cell Shape'</span>, <span class="string">'Marginal Adhesion'</span>, <span class="string">'Single Epithelial Cell Size'</span>, <span class="string">'Bare Nuclei'</span>, <span class="string">'Bland Chromatin'</span>, <span class="string">'Normal Nucleoli'</span>, <span class="string">'Mitoses'</span>, <span class="string">'Class'</span>]</div><div class="line"></div><div class="line"><span class="comment"># 使用pandas.read_csv函数从互联网读取指定数据。</span></div><div class="line">data = pd.read_csv(<span class="string">'https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data'</span>, names = column_names )</div><div class="line"></div><div class="line"><span class="comment"># 将?替换为标准缺失值表示。</span></div><div class="line">data = data.replace(to_replace=<span class="string">'?'</span>, value=np.nan)</div><div class="line"><span class="comment"># 丢弃带有缺失值的数据（只要有一个维度有缺失）。</span></div><div class="line">data = data.dropna(how=<span class="string">'any'</span>)</div><div class="line"></div><div class="line"><span class="comment"># 输出data的数据量和维度。</span></div><div class="line">data.shape</div><div class="line">	</div><div class="line">	(<span class="number">683</span>, <span class="number">11</span>)</div><div class="line"><span class="comment"># 使用sklearn.cross_valiation里的train_test_split模块用于分割数据。</span></div><div class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split</div><div class="line"></div><div class="line"><span class="comment"># 随机采样25%的数据用于测试，剩下的75%用于构建训练集合。</span></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(data[column_names[<span class="number">1</span>:<span class="number">10</span>]], data[column_names[<span class="number">10</span>]], test_size=<span class="number">0.25</span>, random_state=<span class="number">33</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 查验训练样本的数量和类别分布。</span></div><div class="line">y_train.value_counts()</div><div class="line"></div><div class="line">	<span class="number">2</span>    <span class="number">344</span></div><div class="line">	<span class="number">4</span>    <span class="number">168</span></div><div class="line">	Name: Class, dtype: int64</div><div class="line"></div><div class="line"><span class="comment"># 查验测试样本的数量和类别分布。</span></div><div class="line">y_test.value_counts()</div><div class="line"></div><div class="line">	</div><div class="line">Out[<span class="number">4</span>]:</div><div class="line"><span class="number">2</span>    <span class="number">100</span></div><div class="line"><span class="number">4</span>     <span class="number">71</span></div><div class="line">Name: Class, dtype: int64</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 从sklearn.preprocessing里导入StandardScaler。</span></div><div class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</div><div class="line"><span class="comment"># 从sklearn.linear_model里导入LogisticRegression与SGDClassifier。</span></div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</div><div class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> SGDClassifier</div><div class="line"></div><div class="line"><span class="comment"># 标准化数据，保证每个维度的特征数据方差为1，均值为0。使得预测结果不会被某些维度过大的特征值而主导。</span></div><div class="line">ss = StandardScaler()</div><div class="line">X_train = ss.fit_transform(X_train)</div><div class="line">X_test = ss.transform(X_test)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 初始化LogisticRegression与SGDClassifier。</span></div><div class="line">lr = LogisticRegression()</div><div class="line">sgdc = SGDClassifier()</div><div class="line"></div><div class="line"><span class="comment"># 调用LogisticRegression中的fit函数/模块用来训练模型参数。</span></div><div class="line">lr.fit(X_train, y_train)</div><div class="line"><span class="comment"># 使用训练好的模型lr对X_test进行预测，结果储存在变量lr_y_predict中。</span></div><div class="line">lr_y_predict = lr.predict(X_test)</div><div class="line"></div><div class="line"><span class="comment"># 调用SGDClassifier中的fit函数/模块用来训练模型参数。</span></div><div class="line">sgdc.fit(X_train, y_train)</div><div class="line"><span class="comment"># 使用训练好的模型sgdc对X_test进行预测，结果储存在变量sgdc_y_predict中。</span></div><div class="line">sgdc_y_predict = sgdc.predict(X_test)</div><div class="line"></div><div class="line"><span class="comment"># 从sklearn.metrics里导入classification_report模块。</span></div><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</div><div class="line"></div><div class="line"><span class="comment"># 使用逻辑斯蒂回归模型自带的评分函数score获得模型在测试集上的准确性结果。</span></div><div class="line"><span class="keyword">print</span> <span class="string">'Accuracy of LR Classifier:'</span>, lr.score(X_test, y_test)</div><div class="line"><span class="comment"># 利用classification_report模块获得LogisticRegression其他三个指标的结果。</span></div><div class="line"><span class="keyword">print</span> classification_report(y_test, lr_y_predict, target_names=[<span class="string">'Benign'</span>, <span class="string">'Malignant'</span>])</div><div class="line">	Accuracy of LR Classifier: <span class="number">0.988304093567</span></div><div class="line">             precision    recall  f1-score   support</div><div class="line"></div><div class="line">     Benign       <span class="number">0.99</span>      <span class="number">0.99</span>      <span class="number">0.99</span>       <span class="number">100</span></div><div class="line">  Malignant       <span class="number">0.99</span>      <span class="number">0.99</span>      <span class="number">0.99</span>        <span class="number">71</span></div><div class="line"></div><div class="line">avg / total       <span class="number">0.99</span>      <span class="number">0.99</span>      <span class="number">0.99</span>       <span class="number">171</span></div><div class="line"></div><div class="line"> <span class="comment"># 使用随机梯度下降模型自带的评分函数score获得模型在测试集上的准确性结果。</span></div><div class="line"><span class="keyword">print</span> <span class="string">'Accuarcy of SGD Classifier:'</span>, sgdc.score(X_test, y_test)</div><div class="line"><span class="comment"># 利用classification_report模块获得SGDClassifier其他三个指标的结果。</span></div><div class="line"><span class="keyword">print</span> classification_report(y_test, sgdc_y_predict, target_names=[<span class="string">'Benign'</span>, <span class="string">'Malignant'</span>])</div><div class="line"></div><div class="line">	Accuarcy of SGD Classifier: <span class="number">0.953216374269</span></div><div class="line">             precision    recall  f1-score   support</div><div class="line"></div><div class="line">     Benign       <span class="number">0.93</span>      <span class="number">0.99</span>      <span class="number">0.96</span>       <span class="number">100</span></div><div class="line">  Malignant       <span class="number">0.98</span>      <span class="number">0.90</span>      <span class="number">0.94</span>        <span class="number">71</span></div><div class="line"></div><div class="line">avg / total       <span class="number">0.95</span>      <span class="number">0.95</span>      <span class="number">0.95</span>       <span class="number">171</span></div><div class="line">``` </div><div class="line"></div><div class="line"><span class="comment">#### 2.1.1.2 支持向量机(Support Vector Classifier) </span></div><div class="line">![](http://ocef6bnjz.bkt.clouddn.com/<span class="number">17</span><span class="number">-6</span><span class="number">-11</span>/<span class="number">50533102.j</span>pg)</div><div class="line">模型介绍： 例如线性分类可能获得多个线性分类线，但是我们更希望选取更好的那一条，即如上图的H3线，可以对更多的数据点有更好的容忍度。所以支持向量机分类器便是根据训练样本的分布，搜索所有可能的线性分类器中最佳的那个。</div><div class="line">而其中可以用来真正帮助决策最优线性分类器模型的数据点叫做“支持向量”，如上图中的虚线连接的两个点。</div><div class="line">数据描述：</div><div class="line">使用支持向量机分类器处理框架Scikit-learn内部集成的手写数字图片集。</div><div class="line">性能分析：准确率（Accuracy）、召回率（Recall）、精确率（Percision）以及F1指标。需要进一步指出的是以上三个参数最先适用于二分类任务，但是在拥有多个类别的项目中（如此例数据的识别有<span class="number">0</span><span class="number">-9</span>共<span class="number">10</span>个数字），因此无法直接计算上述三个指标，通常的做法是注意评估每个类别的三个指标，也就相当于<span class="number">10</span>个二分类任务。而此学习库也的确是这样的做的。</div><div class="line">特点分析：支持向量机模型在机器学习领域繁荣了一段时间，主要原因在于其精妙的模型假设，可以帮助我们在海量甚至更高维度的数据中筛选出对预测任务最为有效的少数训练样本。这样不仅节省了模型学习所需要的数据内存，同时也提高了模型的预测性能。然后要获得此性能，就必须付出更多的计算代价（CPU资源和计算时间）。</div><div class="line">```python</div><div class="line"><span class="comment"># 从sklearn.datasets里导入手写体数字加载器。</span></div><div class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_digits</div><div class="line"><span class="comment"># 从通过数据加载器获得手写体数字的数码图像数据并储存在digits变量中。</span></div><div class="line">digits = load_digits()</div><div class="line"><span class="comment"># 检视数据规模和特征维度。</span></div><div class="line">digits.data.shape</div><div class="line">	</div><div class="line">	(<span class="number">1797</span>, <span class="number">64</span>）</div><div class="line">	</div><div class="line"><span class="comment"># 从sklearn.cross_validation中导入train_test_split用于数据分割。</span></div><div class="line"><span class="keyword">from</span> sklearn.cross_validation <span class="keyword">import</span> train_test_split</div><div class="line"></div><div class="line"><span class="comment"># 随机选取75%的数据作为训练样本；其余25%的数据作为测试样本。</span></div><div class="line">X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=<span class="number">0.25</span>, random_state=<span class="number">33</span>)</div><div class="line"></div><div class="line">y_train.shape</div><div class="line"></div><div class="line">	(<span class="number">1347</span>,)</div><div class="line">	</div><div class="line">y_test.shape</div><div class="line">	</div><div class="line">	(<span class="number">450</span>,)</div><div class="line">	</div><div class="line"><span class="comment"># 从sklearn.preprocessing里导入数据标准化模块。</span></div><div class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</div><div class="line"></div><div class="line"><span class="comment"># 从sklearn.svm里导入基于线性假设的支持向量机分类器LinearSVC。</span></div><div class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> LinearSVC</div><div class="line"></div><div class="line"><span class="comment"># 从仍然需要对训练和测试的特征数据进行标准化。</span></div><div class="line">ss = StandardScaler()</div><div class="line">X_train = ss.fit_transform(X_train)</div><div class="line">X_test = ss.transform(X_test)</div><div class="line"></div><div class="line"><span class="comment"># 初始化线性假设的支持向量机分类器LinearSVC。</span></div><div class="line">lsvc = LinearSVC()</div><div class="line"><span class="comment">#进行模型训练</span></div><div class="line">lsvc.fit(X_train, y_train)</div><div class="line"><span class="comment"># 利用训练好的模型对测试样本的数字类别进行预测，预测结果储存在变量y_predict中。</span></div><div class="line">y_predict = lsvc.predict(X_test)</div><div class="line"></div><div class="line"><span class="comment"># 使用模型自带的评估函数进行准确性测评。</span></div><div class="line"><span class="keyword">print</span> <span class="string">'The Accuracy of Linear SVC is'</span>, lsvc.score(X_test, y_test)</div><div class="line"></div><div class="line">	The Accuracy of Linear SVC <span class="keyword">is</span> <span class="number">0.953333333333</span></div><div class="line">	</div><div class="line"><span class="comment"># 依然使用sklearn.metrics里面的classification_report模块对预测结果做更加详细的分析。</span></div><div class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> classification_report</div><div class="line"><span class="keyword">print</span> classification_report(y_test, y_predict, target_names=digits.target_names.astype(str))</div><div class="line"></div><div class="line">	 precision    recall  f1-score   support</div><div class="line"></div><div class="line">          <span class="number">0</span>       <span class="number">0.92</span>      <span class="number">1.00</span>      <span class="number">0.96</span>        <span class="number">35</span></div><div class="line">          <span class="number">1</span>       <span class="number">0.96</span>      <span class="number">0.98</span>      <span class="number">0.97</span>        <span class="number">54</span></div><div class="line">          <span class="number">2</span>       <span class="number">0.98</span>      <span class="number">1.00</span>      <span class="number">0.99</span>        <span class="number">44</span></div><div class="line">          <span class="number">3</span>       <span class="number">0.93</span>      <span class="number">0.93</span>      <span class="number">0.93</span>        <span class="number">46</span></div><div class="line">          <span class="number">4</span>       <span class="number">0.97</span>      <span class="number">1.00</span>      <span class="number">0.99</span>        <span class="number">35</span></div><div class="line">          <span class="number">5</span>       <span class="number">0.94</span>      <span class="number">0.94</span>      <span class="number">0.94</span>        <span class="number">48</span></div><div class="line">          <span class="number">6</span>       <span class="number">0.96</span>      <span class="number">0.98</span>      <span class="number">0.97</span>        <span class="number">51</span></div><div class="line">          <span class="number">7</span>       <span class="number">0.92</span>      <span class="number">1.00</span>      <span class="number">0.96</span>        <span class="number">35</span></div><div class="line">          <span class="number">8</span>       <span class="number">0.98</span>      <span class="number">0.84</span>      <span class="number">0.91</span>        <span class="number">58</span></div><div class="line">          <span class="number">9</span>       <span class="number">0.95</span>      <span class="number">0.91</span>      <span class="number">0.93</span>        <span class="number">44</span></div><div class="line"></div><div class="line">avg / total       <span class="number">0.95</span>      <span class="number">0.95</span>      <span class="number">0.95</span>       <span class="number">450</span></div></pre></td></tr></table></figure></p>
<h4 id="2-1-1-3-朴素贝叶斯-Native-Bayes"><a href="#2-1-1-3-朴素贝叶斯-Native-Bayes" class="headerlink" title="2.1.1.3 朴素贝叶斯(Native Bayes)"></a>2.1.1.3 朴素贝叶斯(Native Bayes)</h4><p>模型介绍：<br>朴素贝叶斯是一个非常简单，但是实用性很强的分类模型，不过和基于线性假设的（线性分类器、支持向量机）不同，朴素贝叶斯分类器的构造基础是贝叶斯理论。<br><img src="http://ocef6bnjz.bkt.clouddn.com/17-6-11/75506981.jpg" alt=""><br>数据描述：<br>朴素贝叶斯模型有着广泛的应用环境，特别是在文本分类的任务中间，包括互联网新闻的分类、垃圾邮件的筛选等。本次实例就采取新闻文本作为实验数据。<br>性能分析：<br>准确率（Accuracy）、召回率（Recall）、精确率（Percision）以及F1指标。通过这个测度对朴素贝叶斯模型在20类新闻文本分类任务上的性能进行评估。<br>特点分析：<br>朴素贝叶斯模型被广泛的运用于海量互联网文本分类任务。由于其较强的特征条件独立假设，使得模型预测所需估计的参数规模从幂指数向线性量级别减少，极大的节约了内存消耗和计算时间。但是也正因为这种强假设的限制，模型训练无法将各个特征之间的联系考量在内，使得该模型在其他数据特征关联性较强的分类任务上的性能表现不佳。</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div></pre></td><td class="code"><pre><div class="line"># 从sklearn.datasets里导入新闻数据抓取器fetch_20newsgroups。</div><div class="line">from sklearn.datasets import fetch_20newsgroups</div><div class="line"># 与之前预存的数据不同，fetch_20newsgroups需要即时从互联网下载数据。</div><div class="line">news = fetch_20newsgroups(subset='all')</div><div class="line"># 查验数据规模和细节。</div><div class="line">print len(news.data)</div><div class="line">print news.data[0]</div><div class="line">	</div><div class="line">	WARNING:sklearn.datasets.twenty_newsgroups:Downloading dataset from http://people.csail.mit.edu/jrennie/20Newsgroups/20news-bydate.tar.gz (14 MB)</div><div class="line">	18846</div><div class="line">	From: Mamatha Devineni Ratnam &lt;mr47+@andrew.cmu.edu&gt;</div><div class="line">	Subject: Pens fans reactions</div><div class="line">	Organization: Post Office, Carnegie Mellon, Pittsburgh, PA</div><div class="line">	Lines: 12</div><div class="line">	NNTP-Posting-Host: po4.andrew.cmu.edu</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">	I am sure some bashers of Pens fans are pretty confused about the lack</div><div class="line">	of any kind of posts about the recent Pens massacre of the Devils. Actually,</div><div class="line">	I am  bit puzzled too and a bit relieved. However, I am going to put an end</div><div class="line">	to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they</div><div class="line">	are killing those Devils worse than I thought. Jagr just showed you why</div><div class="line">	he is much better than his regular season stats. He is also a lot</div><div class="line">	fo fun to watch in the playoffs. Bowman should let JAgr have a lot of</div><div class="line">	fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final</div><div class="line">	regular season game.          PENS RULE!!!</div><div class="line">	</div><div class="line"># 从sklearn.cross_validation 导入 train_test_split。</div><div class="line">from sklearn.cross_validation import train_test_split</div><div class="line"># 随机采样25%的数据样本作为测试集。</div><div class="line">X_train, X_test, y_train, y_test = train_test_split(news.data, news.target, test_size=0.25, random_state=33)</div><div class="line"></div><div class="line"># 从sklearn.feature_extraction.text里导入用于文本特征向量转化模块。详细介绍请读者参考3.1.1.1 特征抽取一节。</div><div class="line">from sklearn.feature_extraction.text import CountVectorizer</div><div class="line"></div><div class="line">vec = CountVectorizer()</div><div class="line">X_train = vec.fit_transform(X_train)</div><div class="line">X_test = vec.transform(X_test)</div><div class="line"></div><div class="line"># 从sklearn.naive_bayes里导入朴素贝叶斯模型。</div><div class="line">from sklearn.naive_bayes import MultinomialNB</div><div class="line"></div><div class="line"># 从使用默认配置初始化朴素贝叶斯模型。</div><div class="line">mnb = MultinomialNB()</div><div class="line"># 利用训练数据对模型参数进行估计。</div><div class="line">mnb.fit(X_train, y_train)</div><div class="line"># 对测试样本进行类别预测，结果存储在变量y_predict中。</div><div class="line">y_predict = mnb.predict(X_test)</div><div class="line"></div><div class="line"># 从sklearn.metrics里导入classification_report用于详细的分类性能报告。</div><div class="line">from sklearn.metrics import classification_report</div><div class="line">print 'The accuracy of Naive Bayes Classifier is', mnb.score(X_test, y_test)</div><div class="line">print classification_report(y_test, y_predict, target_names = news.target_names)</div><div class="line"></div><div class="line">	The accuracy of Naive Bayes Classifier is 0.839770797963</div><div class="line">							  precision    recall  f1-score   support</div><div class="line"></div><div class="line">				 alt.atheism       0.86      0.86      0.86       201</div><div class="line">			   comp.graphics       0.59      0.86      0.70       250</div><div class="line">	 comp.os.ms-windows.misc       0.89      0.10      0.17       248</div><div class="line">	comp.sys.ibm.pc.hardware       0.60      0.88      0.72       240</div><div class="line">	   comp.sys.mac.hardware       0.93      0.78      0.85       242</div><div class="line">			  comp.windows.x       0.82      0.84      0.83       263</div><div class="line">				misc.forsale       0.91      0.70      0.79       257</div><div class="line">				   rec.autos       0.89      0.89      0.89       238</div><div class="line">			 rec.motorcycles       0.98      0.92      0.95       276</div><div class="line">		  rec.sport.baseball       0.98      0.91      0.95       251</div><div class="line">			rec.sport.hockey       0.93      0.99      0.96       233</div><div class="line">				   sci.crypt       0.86      0.98      0.91       238</div><div class="line">			 sci.electronics       0.85      0.88      0.86       249</div><div class="line">					 sci.med       0.92      0.94      0.93       245</div><div class="line">				   sci.space       0.89      0.96      0.92       221</div><div class="line">	  soc.religion.christian       0.78      0.96      0.86       232</div><div class="line">		  talk.politics.guns       0.88      0.96      0.92       251</div><div class="line">	   talk.politics.mideast       0.90      0.98      0.94       231</div><div class="line">		  talk.politics.misc       0.79      0.89      0.84       188</div><div class="line">		  talk.religion.misc       0.93      0.44      0.60       158</div><div class="line"></div><div class="line">				 avg / total       0.86      0.84      0.82      4712</div></pre></td></tr></table></figure>
<h4 id="2-1-1-4-K近邻-K-Nearest-Neighbor"><a href="#2-1-1-4-K近邻-K-Nearest-Neighbor" class="headerlink" title="2.1.1.4 K近邻(K-Nearest Neighbor)"></a>2.1.1.4 K近邻(K-Nearest Neighbor)</h4><p>模型介绍：<br><img src="http://ocef6bnjz.bkt.clouddn.com/17-6-11/17242026.jpg" alt=""><br>假设有一些携带分类标记的训练样本，分布于特征空间中。（有三类颜色蓝绿红，但图黑白将就看吧），不同颜色代表各自的类别，对于一个待分类的样本，选取待分类样本在特征空间中距离最近的K个已标记样本作为参考，来帮助做出分类决策。因此可以得知K值不同得到的分类器可能不同。<br>数据描述：<br>使用K临近算法对生物物种进行分类，并且使用最为著名的鸢尾数据集。<br>性能分析：<br>准确率（Accuracy）、召回率（Recall）、精确率（Percision）以及F1指标。通过这个测度对朴素贝叶斯模型在20类新闻文本分类任务上的性能进行评估。<br>特点分析：<br>K临近分类是非常直观的机器学习模型，K临近算法与其他模型的最大不同在于该模型没有参数训练过程。也就是说没有通过任何学习算法分析训练数据，而只是根据测试样本在训练数据的分布直接作出决策。所以K临近算法属于无参数模型中非常简单的一种。但是这样的决策算法导致了非常高的计算复杂度和内存消耗。因为该模型每处理一个测试样本都需要对所有预先加载在内存的训练样本进行遍历、逐一计算相似度、排序并且选取K个最近邻训练样本的标记，进而做出决策。这是平方级别的算法复杂度，一旦数据量较大，时间消耗会很大。<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div></pre></td><td class="code"><pre><div class="line"># 从sklearn.datasets 导入 iris数据加载器。</div><div class="line">from sklearn.datasets import load_iris</div><div class="line"># 使用加载器读取数据并且存入变量iris。</div><div class="line">iris = load_iris()</div><div class="line"># 查验数据规模。</div><div class="line">iris.data.shape</div><div class="line"></div><div class="line">	(150L, 4L)</div><div class="line"></div><div class="line"># 查看数据说明。对于一名机器学习的实践者来讲，这是一个好习惯。</div><div class="line">print iris.DESCR</div><div class="line">	</div><div class="line">	Iris Plants Database</div><div class="line"></div><div class="line">	Notes</div><div class="line">	-----</div><div class="line">	Data Set Characteristics:</div><div class="line">		:Number of Instances: 150 (50 in each of three classes)</div><div class="line">		:Number of Attributes: 4 numeric, predictive attributes and the class</div><div class="line">		:Attribute Information:</div><div class="line">			- sepal length in cm</div><div class="line">			- sepal width in cm</div><div class="line">			- petal length in cm</div><div class="line">			- petal width in cm</div><div class="line">			- class:</div><div class="line">					- Iris-Setosa</div><div class="line">					- Iris-Versicolour</div><div class="line">					- Iris-Virginica</div><div class="line">		:Summary Statistics:</div><div class="line"></div><div class="line">		============== ==== ==== ======= ===== ====================</div><div class="line">						Min  Max   Mean    SD   Class Correlation</div><div class="line">		============== ==== ==== ======= ===== ====================</div><div class="line">		sepal length:   4.3  7.9   5.84   0.83    0.7826</div><div class="line">		sepal width:    2.0  4.4   3.05   0.43   -0.4194</div><div class="line">		petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)</div><div class="line">		petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)</div><div class="line">		============== ==== ==== ======= ===== ====================</div><div class="line"></div><div class="line">		:Missing Attribute Values: None</div><div class="line">		:Class Distribution: 33.3% for each of 3 classes.</div><div class="line">		:Creator: R.A. Fisher</div><div class="line">		:Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)</div><div class="line">		:Date: July, 1988</div><div class="line"></div><div class="line">	This is a copy of UCI ML iris datasets.</div><div class="line">	http://archive.ics.uci.edu/ml/datasets/Iris</div><div class="line"></div><div class="line">	The famous Iris database, first used by Sir R.A Fisher</div><div class="line"></div><div class="line">	This is perhaps the best known database to be found in the</div><div class="line">	pattern recognition literature.  Fisher's paper is a classic in the field and</div><div class="line">	is referenced frequently to this day.  (See Duda &amp; Hart, for example.)  The</div><div class="line">	data set contains 3 classes of 50 instances each, where each class refers to a</div><div class="line">	type of iris plant.  One class is linearly separable from the other 2; the</div><div class="line">	latter are NOT linearly separable from each other.</div><div class="line"></div><div class="line">	References</div><div class="line">	----------</div><div class="line">	   - Fisher,R.A. "The use of multiple measurements in taxonomic problems"</div><div class="line">		 Annual Eugenics, 7, Part II, 179-188 (1936); also in "Contributions to</div><div class="line">		 Mathematical Statistics" (John Wiley, NY, 1950).</div><div class="line">	   - Duda,R.O., &amp; Hart,P.E. (1973) Pattern Classification and Scene Analysis.</div><div class="line">		 (Q327.D83) John Wiley &amp; Sons.  ISBN 0-471-22361-1.  See page 218.</div><div class="line">	   - Dasarathy, B.V. (1980) "Nosing Around the Neighborhood: A New System</div><div class="line">		 Structure and Classification Rule for Recognition in Partially Exposed</div><div class="line">		 Environments".  IEEE Transactions on Pattern Analysis and Machine</div><div class="line">		 Intelligence, Vol. PAMI-2, No. 1, 67-71.</div><div class="line">	   - Gates, G.W. (1972) "The Reduced Nearest Neighbor Rule".  IEEE Transactions</div><div class="line">		 on Information Theory, May 1972, 431-433.</div><div class="line">	   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al"s AUTOCLASS II</div><div class="line">		 conceptual clustering system finds 3 classes in the data.</div><div class="line">	   - Many, many more ...</div><div class="line">	   </div><div class="line"># 从sklearn.cross_validation里选择导入train_test_split用于数据分割。</div><div class="line">from sklearn.cross_validation import train_test_split</div><div class="line"># 从使用train_test_split，利用随机种子random_state采样25%的数据作为测试集。</div><div class="line">X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.25, random_state=33)</div><div class="line"></div><div class="line"># 从sklearn.preprocessing里选择导入数据标准化模块。</div><div class="line">from sklearn.preprocessing import StandardScaler</div><div class="line"># 从sklearn.neighbors里选择导入KNeighborsClassifier，即K近邻分类器。</div><div class="line">from sklearn.neighbors import KNeighborsClassifier</div><div class="line"></div><div class="line"># 对训练和测试的特征数据进行标准化。</div><div class="line">ss = StandardScaler()</div><div class="line">X_train = ss.fit_transform(X_train)</div><div class="line">X_test = ss.transform(X_test)</div><div class="line"></div><div class="line"># 使用K近邻分类器对测试数据进行类别预测，预测结果储存在变量y_predict中。</div><div class="line">knc = KNeighborsClassifier()</div><div class="line">knc.fit(X_train, y_train)</div><div class="line">y_predict = knc.predict(X_test)</div><div class="line"></div><div class="line"># 使用模型自带的评估函数进行准确性测评。</div><div class="line">print 'The accuracy of K-Nearest Neighbor Classifier is', knc.score(X_test, y_test) </div><div class="line"></div><div class="line">	The accuracy of K-Nearest Neighbor Classifier is 0.894736842105</div><div class="line"></div><div class="line"># 依然使用sklearn.metrics里面的classification_report模块对预测结果做更加详细的分析。</div><div class="line">from sklearn.metrics import classification_report</div><div class="line">print classification_report(y_test, y_predict, target_names=iris.target_names)</div><div class="line"></div><div class="line">			  precision    recall  f1-score   support</div><div class="line"></div><div class="line">			 setosa       1.00      1.00      1.00         8</div><div class="line">		 versicolor       0.73      1.00      0.85        11</div><div class="line">		  virginica       1.00      0.79      0.88        19</div><div class="line"></div><div class="line">		avg / total       0.92      0.89      0.90        38</div></pre></td></tr></table></figure></p>
<h4 id="2-1-1-5-决策树-Decision-Tree"><a href="#2-1-1-5-决策树-Decision-Tree" class="headerlink" title="2.1.1.5 决策树(Decision Tree)"></a>2.1.1.5 决策树(Decision Tree)</h4><p>模型介绍：<br>数据描述：<br>性能分析：<br>特点分析：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 导入pandas用于数据分析。</span></div><div class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</div><div class="line"><span class="comment"># 利用pandas的read_csv模块直接从互联网收集泰坦尼克号乘客数据。</span></div><div class="line">titanic = pd.read_csv(<span class="string">'http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt'</span>)</div><div class="line"></div><div class="line"><span class="comment"># 观察一下前几行数据，可以发现，数据种类各异，数值型、类别型，甚至还有缺失数据。</span></div><div class="line">titanic.head()</div><div class="line">	row.names	pclass	survived	name										age	embarked	home.dest										room		ticket	boat	sex</div><div class="line">	<span class="number">0</span>	<span class="number">1</span>		<span class="number">1</span>st			<span class="number">1</span>	Allen, Miss Elisabeth Walton					<span class="number">29.0000</span>			Southampton	St Louis, MO						B<span class="number">-5</span>		<span class="number">24160</span> L221	<span class="number">2</span>		female</div><div class="line">	<span class="number">1</span>	<span class="number">2</span>		<span class="number">1</span>st			<span class="number">0</span>	Allison, Miss Helen Loraine						<span class="number">2.0000</span>			Southampton	Montreal, PQ / Chesterville, ON		C26			NaN		NaN		female</div><div class="line">	<span class="number">2</span>	<span class="number">3</span>		<span class="number">1</span>st			<span class="number">0</span>	Allison, Mr Hudson Joshua Creighton				<span class="number">30.0000</span>			Southampton	Montreal, PQ / Chesterville, ON		C26			NaN		(<span class="number">135</span>)	male</div><div class="line">	<span class="number">3</span>	<span class="number">4</span>		<span class="number">1</span>st			<span class="number">0</span>	Allison, Mrs Hudson J.C. (Bessie Waldo Daniels)	<span class="number">25.0000</span>			Southampton	Montreal, PQ / Chesterville, ON		C26			NaN		NaN		female</div><div class="line">	<span class="number">4</span>	<span class="number">5</span>		<span class="number">1</span>st			<span class="number">1</span>	Allison, Master Hudson Trevor	<span class="number">0.9167</span>	Southampton	Montreal, PQ / Chesterville, ON	C22	NaN	<span class="number">11</span>	male</div></pre></td></tr></table></figure></p>
<h4 id="2-1-1-6-集成模型-Ensemble-随机森林：Random-Forest-Classifier，梯度提升决策树：Gradient-Tree-Boosting。"><a href="#2-1-1-6-集成模型-Ensemble-随机森林：Random-Forest-Classifier，梯度提升决策树：Gradient-Tree-Boosting。" class="headerlink" title="2.1.1.6 集成模型(Ensemble):随机森林：Random Forest Classifier，梯度提升决策树：Gradient Tree Boosting。"></a>2.1.1.6 集成模型(Ensemble):随机森林：Random Forest Classifier，梯度提升决策树：Gradient Tree Boosting。</h4><p>模型介绍：<br>数据描述：<br>性能分析：<br>特点分析：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">```</div><div class="line"><span class="comment">### 2.1.2 回归预测（Regressor） </span></div><div class="line"><span class="comment">#### 2.1.2.1 线性回归器 </span></div><div class="line">模型介绍： </div><div class="line">数据描述：</div><div class="line">性能分析：</div><div class="line">特点分析：</div><div class="line">```python</div></pre></td></tr></table></figure></p>
<h4 id="2-1-2-2-支持向量机"><a href="#2-1-2-2-支持向量机" class="headerlink" title="2.1.2.2 支持向量机"></a>2.1.2.2 支持向量机</h4><p>模型介绍：<br>数据描述：<br>性能分析：<br>特点分析：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">```</div><div class="line"><span class="comment">#### 2.1.2.3 K近邻 </span></div><div class="line">模型介绍： </div><div class="line">数据描述：</div><div class="line">性能分析：</div><div class="line">特点分析：</div><div class="line">```python</div></pre></td></tr></table></figure></p>
<h4 id="2-1-2-4-回归树"><a href="#2-1-2-4-回归树" class="headerlink" title="2.1.2.4 回归树"></a>2.1.2.4 回归树</h4><p>模型介绍：<br>数据描述：<br>性能分析：<br>特点分析：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">```</div><div class="line"><span class="comment">#### 2.1.2.5 集成模型 </span></div><div class="line">模型介绍： </div><div class="line">数据描述：</div><div class="line">性能分析：</div><div class="line">特点分析：</div><div class="line">```python</div></pre></td></tr></table></figure></p>
<h2 id="2-2-无监督学习"><a href="#2-2-无监督学习" class="headerlink" title="2.2 无监督学习"></a>2.2 无监督学习</h2><h3 id="2-2-1-数据聚类"><a href="#2-2-1-数据聚类" class="headerlink" title="2.2.1 数据聚类"></a>2.2.1 数据聚类</h3><p>模型介绍：<br>数据描述：<br>性能分析：<br>特点分析：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">```</div><div class="line"><span class="comment">#### 2.2.1.1 K均值算法(K-means) </span></div><div class="line">模型介绍： </div><div class="line">数据描述：</div><div class="line">性能分析：</div><div class="line">特点分析：</div><div class="line">```python</div></pre></td></tr></table></figure></p>
<h4 id="2-2-2-特征降维"><a href="#2-2-2-特征降维" class="headerlink" title="2.2.2 特征降维"></a>2.2.2 特征降维</h4><p>模型介绍：<br>数据描述：<br>性能分析：<br>特点分析：</p>
<pre><code class="python">
</code></pre>
<h4 id="2-2-2-1-主成分分析-Principal-Component-Analysis-PCA"><a href="#2-2-2-1-主成分分析-Principal-Component-Analysis-PCA" class="headerlink" title="2.2.2.1 主成分分析(Principal Component Analysis:PCA)"></a>2.2.2.1 主成分分析(Principal Component Analysis:PCA)</h4><h2 id="3-1-模型使用技巧"><a href="#3-1-模型使用技巧" class="headerlink" title="3.1 模型使用技巧"></a>3.1 模型使用技巧</h2><h3 id="3-1-1-特征提升"><a href="#3-1-1-特征提升" class="headerlink" title="3.1.1 特征提升"></a>3.1.1 特征提升</h3><h4 id="3-1-1-1-特征抽取"><a href="#3-1-1-1-特征抽取" class="headerlink" title="3.1.1.1 特征抽取"></a>3.1.1.1 特征抽取</h4><h4 id="3-1-1-2-特征筛选"><a href="#3-1-1-2-特征筛选" class="headerlink" title="3.1.1.2 特征筛选"></a>3.1.1.2 特征筛选</h4><h3 id="3-1-2-模型正则化"><a href="#3-1-2-模型正则化" class="headerlink" title="3.1.2 模型正则化"></a>3.1.2 模型正则化</h3><h4 id="3-1-2-1-欠拟合与过拟合"><a href="#3-1-2-1-欠拟合与过拟合" class="headerlink" title="3.1.2.1 欠拟合与过拟合"></a>3.1.2.1 欠拟合与过拟合</h4><h4 id="3-1-2-2-L-1-范数正则化"><a href="#3-1-2-2-L-1-范数正则化" class="headerlink" title="3.1.2.2 L 1  范数正则化"></a>3.1.2.2 L 1  范数正则化</h4><h4 id="3-1-2-3-L-2-范数正则化"><a href="#3-1-2-3-L-2-范数正则化" class="headerlink" title="3.1.2.3 L 2  范数正则化"></a>3.1.2.3 L 2  范数正则化</h4><h3 id="3-1-3-模型检验"><a href="#3-1-3-模型检验" class="headerlink" title="3.1.3 模型检验"></a>3.1.3 模型检验</h3><h4 id="3-1-3-1-留一验证"><a href="#3-1-3-1-留一验证" class="headerlink" title="3.1.3.1 留一验证"></a>3.1.3.1 留一验证</h4><h4 id="3-1-3-2-交叉验证"><a href="#3-1-3-2-交叉验证" class="headerlink" title="3.1.3.2 交叉验证"></a>3.1.3.2 交叉验证</h4><h3 id="3-1-4-超参数搜索"><a href="#3-1-4-超参数搜索" class="headerlink" title="3.1.4 超参数搜索"></a>3.1.4 超参数搜索</h3><h4 id="3-1-4-1-网格搜索"><a href="#3-1-4-1-网格搜索" class="headerlink" title="3.1.4.1 网格搜索"></a>3.1.4.1 网格搜索</h4><h4 id="3-1-4-2-并行搜索"><a href="#3-1-4-2-并行搜索" class="headerlink" title="3.1.4.2 并行搜索"></a>3.1.4.2 并行搜索</h4><h2 id="3-2-流行库-模型实践"><a href="#3-2-流行库-模型实践" class="headerlink" title="3.2 流行库/模型实践"></a>3.2 流行库/模型实践</h2><h3 id="自然语言包：NLTK"><a href="#自然语言包：NLTK" class="headerlink" title="自然语言包：NLTK"></a>自然语言包：NLTK</h3><h3 id="词向量：Word2Vec"><a href="#词向量：Word2Vec" class="headerlink" title="词向量：Word2Vec"></a>词向量：Word2Vec</h3><h3 id="XGBoost模型"><a href="#XGBoost模型" class="headerlink" title="XGBoost模型"></a>XGBoost模型</h3><h3 id="TensorFlow"><a href="#TensorFlow" class="headerlink" title="TensorFlow"></a>TensorFlow</h3>
      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div>坚持原创技术分享，您的支持将鼓励我继续创作！</div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="/personnal/wechat-reward-image.jpg" alt="FangHeart WeChat Pay"/>
          <p>微信打赏</p>
        </div>
      
      
        <div id="alipay" style="display: inline-block">
          <img id="alipay_qr" src="/personnal/alipay-reward-image.jpg" alt="FangHeart Alipay"/>
          <p>支付宝打赏</p>
        </div>
      
    </div>
  </div>


      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
          
            <a href="/tags/有监督学习/" rel="tag"># 有监督学习</a>
          
            <a href="/tags/无监督学习/" rel="tag"># 无监督学习</a>
          
            <a href="/tags/线性分类器/" rel="tag"># 线性分类器</a>
          
            <a href="/tags/SVM支持向量机/" rel="tag"># SVM支持向量机</a>
          
            <a href="/tags/logistic回归/" rel="tag"># logistic回归</a>
          
            <a href="/tags/随机梯度/" rel="tag"># 随机梯度</a>
          
            <a href="/tags/贝叶斯模型/" rel="tag"># 贝叶斯模型</a>
          
            <a href="/tags/K邻近/" rel="tag"># K邻近</a>
          
            <a href="/tags/决策树/" rel="tag"># 决策树</a>
          
            <a href="/tags/集成模型/" rel="tag"># 集成模型</a>
          
            <a href="/tags/随机森林/" rel="tag"># 随机森林</a>
          
            <a href="/tags/极端随机森林/" rel="tag"># 极端随机森林</a>
          
            <a href="/tags/梯度提升决策树/" rel="tag"># 梯度提升决策树</a>
          
            <a href="/tags/数据聚类（K-means）/" rel="tag"># 数据聚类（K-means）</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/05/16/java语言基础-反射、动态代理、JDK新特性/" rel="next" title="java语言基础_反射、动态代理、JDK新特性">
                <i class="fa fa-chevron-left"></i> java语言基础_反射、动态代理、JDK新特性
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="cloud-tie-wrapper" class="cloud-tie-wrapper"></div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/personnal/author.jpg"
               alt="FangHeart" />
          <p class="site-author-name" itemprop="name">FangHeart</p>
           
              <p class="site-description motion-element" itemprop="description">不忘初心，方得始终。</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">38</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">9</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">38</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/fangheart" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/2013845927/" target="_blank" title="微博">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  微博
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://www.zhihu.com/people/fangheart" target="_blank" title="知乎">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  知乎
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="mailto:fangheart@fangheart.win" target="_blank" title="邮箱">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                  邮箱
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://haroldliu.weebly.com" title="HaroldLiuChi" target="_blank">HaroldLiuChi</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://guangyugao.weebly.com/" title="GaoGuangYu" target="_blank">GaoGuangYu</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://wenjiewang.top" title="WenJieWang" target="_blank">WenJieWang</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://blog.csdn.net/it_dx" title="DuanXiong" target="_blank">DuanXiong</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://dongxicheng.org/recommend/" title="DongXiCheng" target="_blank">DongXiCheng</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#基本知识"><span class="nav-number">1.</span> <span class="nav-text">基本知识</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-1-机器学习的任务"><span class="nav-number">1.1.</span> <span class="nav-text">1.1.1 机器学习的任务</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-2-机器学习中应用的经验"><span class="nav-number">1.2.</span> <span class="nav-text">1.1.2 机器学习中应用的经验</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-3-机器学习的性能、精度表现形式"><span class="nav-number">1.3.</span> <span class="nav-text">1.1.3 机器学习的性能、精度表现形式</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#监督学习："><span class="nav-number">2.</span> <span class="nav-text">监督学习：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-1分类学习（Classifier）"><span class="nav-number">2.1.</span> <span class="nav-text">2.1.1分类学习（Classifier）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-1-1-线性分类器（Linear-Classifier）"><span class="nav-number">2.1.1.</span> <span class="nav-text">2.1.1.1 线性分类器（Linear Classifier）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-1-3-朴素贝叶斯-Native-Bayes"><span class="nav-number">2.1.2.</span> <span class="nav-text">2.1.1.3 朴素贝叶斯(Native Bayes)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-1-4-K近邻-K-Nearest-Neighbor"><span class="nav-number">2.1.3.</span> <span class="nav-text">2.1.1.4 K近邻(K-Nearest Neighbor)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-1-5-决策树-Decision-Tree"><span class="nav-number">2.1.4.</span> <span class="nav-text">2.1.1.5 决策树(Decision Tree)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-1-6-集成模型-Ensemble-随机森林：Random-Forest-Classifier，梯度提升决策树：Gradient-Tree-Boosting。"><span class="nav-number">2.1.5.</span> <span class="nav-text">2.1.1.6 集成模型(Ensemble):随机森林：Random Forest Classifier，梯度提升决策树：Gradient Tree Boosting。</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-2-2-支持向量机"><span class="nav-number">2.1.6.</span> <span class="nav-text">2.1.2.2 支持向量机</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-2-4-回归树"><span class="nav-number">2.1.7.</span> <span class="nav-text">2.1.2.4 回归树</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-无监督学习"><span class="nav-number">3.</span> <span class="nav-text">2.2 无监督学习</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-1-数据聚类"><span class="nav-number">3.1.</span> <span class="nav-text">2.2.1 数据聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-2-特征降维"><span class="nav-number">3.1.1.</span> <span class="nav-text">2.2.2 特征降维</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-2-1-主成分分析-Principal-Component-Analysis-PCA"><span class="nav-number">3.1.2.</span> <span class="nav-text">2.2.2.1 主成分分析(Principal Component Analysis:PCA)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-模型使用技巧"><span class="nav-number">4.</span> <span class="nav-text">3.1 模型使用技巧</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-1-特征提升"><span class="nav-number">4.1.</span> <span class="nav-text">3.1.1 特征提升</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-1-1-特征抽取"><span class="nav-number">4.1.1.</span> <span class="nav-text">3.1.1.1 特征抽取</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-1-2-特征筛选"><span class="nav-number">4.1.2.</span> <span class="nav-text">3.1.1.2 特征筛选</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-2-模型正则化"><span class="nav-number">4.2.</span> <span class="nav-text">3.1.2 模型正则化</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-2-1-欠拟合与过拟合"><span class="nav-number">4.2.1.</span> <span class="nav-text">3.1.2.1 欠拟合与过拟合</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-2-2-L-1-范数正则化"><span class="nav-number">4.2.2.</span> <span class="nav-text">3.1.2.2 L 1  范数正则化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-2-3-L-2-范数正则化"><span class="nav-number">4.2.3.</span> <span class="nav-text">3.1.2.3 L 2  范数正则化</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-3-模型检验"><span class="nav-number">4.3.</span> <span class="nav-text">3.1.3 模型检验</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-3-1-留一验证"><span class="nav-number">4.3.1.</span> <span class="nav-text">3.1.3.1 留一验证</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-3-2-交叉验证"><span class="nav-number">4.3.2.</span> <span class="nav-text">3.1.3.2 交叉验证</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-4-超参数搜索"><span class="nav-number">4.4.</span> <span class="nav-text">3.1.4 超参数搜索</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-4-1-网格搜索"><span class="nav-number">4.4.1.</span> <span class="nav-text">3.1.4.1 网格搜索</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-4-2-并行搜索"><span class="nav-number">4.4.2.</span> <span class="nav-text">3.1.4.2 并行搜索</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-流行库-模型实践"><span class="nav-number">5.</span> <span class="nav-text">3.2 流行库/模型实践</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#自然语言包：NLTK"><span class="nav-number">5.1.</span> <span class="nav-text">自然语言包：NLTK</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#词向量：Word2Vec"><span class="nav-number">5.2.</span> <span class="nav-text">词向量：Word2Vec</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#XGBoost模型"><span class="nav-number">5.3.</span> <span class="nav-text">XGBoost模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#TensorFlow"><span class="nav-number">5.4.</span> <span class="nav-text">TensorFlow</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2016 - 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-FangHeart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">FangHeart</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>


        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  

  

  <span id="busuanzi_container_site_uv">
  本站访客数22<span id="busuanzi_value_site_uv"></span>人次
</span>

<span id="busuanzi_container_site_pv">
    本站总访问量52<span id="busuanzi_value_site_pv"></span>次
</span>
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  




	





  
    
    <script>
      var cloudTieConfig = {
        url: document.location.href, 
        sourceId: "",
        productKey: "eb7c3e4313a441e99919491234887c0d",
        target: "cloud-tie-wrapper"
      };
    </script>
    <script src="https://img1.ws.126.net/f2e/tie/yun/sdk/loader.js"></script>
  










  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.popup').toggle();
    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("EFaViLzEeIm1xLj3lRgl6Ktw-gzGzoHsz", "6QrsfTcpIvP6XuQ8mKM70tx9");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  
  


  

  <!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/love.js"></script>
<!-- 背景动画 -->
<script type="text/javascript" src="/js/src/particle.js"></script>

</body>
</html>
